===================================================================================
                    üéØ INTERVIEW PREPARATION IMPLEMENTATION
===================================================================================

üìñ WHAT IS THIS?
---------------
This document explains how the AI-powered interview preparation guide is generated.

===================================================================================
                         SECTION 1: OVERVIEW
===================================================================================

Q: What does interview preparation do?
-------------------------------------
A: Generates a comprehensive, personalized interview guide including:
   - Company research and interview links
   - Interview rounds breakdown (DSA, System Design, Behavioral)
   - DSA preparation (20-30 topics, role-specific)
   - System Design concepts (if applicable)
   - Behavioral prep with STAR format
   - Common Q&A with sample answers
   - Resources and tips

Q: Why use LangGraph?
--------------------
A: Interview prep requires multiple steps:
   1. Research company (web search)
   2. Analyze interview rounds (LLM analysis)
   3. Prepare content for each round (LLM generation)
   4. Generate common questions (LLM generation)
   
   LangGraph orchestrates these steps in a structured workflow.

===================================================================================
                         SECTION 2: LANGGRAPH WORKFLOW
===================================================================================

üìÅ FILE: AI/interview_prep_graph.py

WORKFLOW STRUCTURE:
-------------------
4-Node LangGraph:

START ‚Üí company_research ‚Üí interview_rounds_analyzer ‚Üí 
        round_by_round_prep ‚Üí question_generator ‚Üí END

NODE 1: COMPANY RESEARCH
-------------------------
Function: company_research_node(state)

What it does:
1. Extracts company name and job title from job data
2. Searches web using Tavily API for:
   - Company information
   - Interview experiences (Reddit, Glassdoor, LeetCode)
   - Recent news about company
3. Extracts 2 interview links from search results
4. Determines role level (Fresher, SDE-1, SDE-2, Senior)

Code Flow:
----------
def company_research_node(state: InterviewPrepState) -> Dict[str, Any]:
    job_data = state.get("job_data", {})
    company = job_data.get("company", "")
    title = job_data.get("title", "")
    
    # 1. Search for company info
    company_search = smart_web_search(f"{company} company information culture")
    
    # 2. Search for interview experiences
    interview_search = smart_web_search(
        f"{company} {title} interview experience reddit glassdoor leetcode"
    )
    
    # 3. Extract interview links
    interview_links = extract_interview_links(interview_search)
    
    # 4. Determine role level
    role_level = determine_role_level(title)
    
    return {
        "company_info": company_search,
        "interview_links": interview_links[:2],  # Top 2 links
        "role_level": role_level
    }

NODE 2: INTERVIEW ROUNDS ANALYZER
----------------------------------
Function: interview_rounds_analyzer_node(state)

What it does:
1. Analyzes job description and role level
2. Determines typical interview process:
   - Number of rounds
   - Types of rounds (DSA, System Design, Behavioral)
   - Duration of each round
3. Creates structured breakdown

Code Flow:
----------
def interview_rounds_analyzer_node(state: InterviewPrepState) -> Dict[str, Any]:
    job_data = state.get("job_data", {})
    role_level = state.get("role_level", "SDE-1")
    company = job_data.get("company", "")
    
    prompt = f"""
    Analyze interview process for {role_level} role at {company}.
    Job Description: {job_data.get("description", "")}
    
    Determine:
    1. Total number of rounds
    2. Types of rounds (DSA, System Design, Behavioral, etc.)
    3. Duration of each round
    4. Order of rounds
    """
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are an interview process expert"},
            {"role": "user", "content": prompt}
        ]
    )
    
    interview_rounds = parse_interview_rounds(response.choices[0].message.content)
    
    return {"interview_rounds": interview_rounds}

NODE 3: ROUND-BY-ROUND PREPARATION
-----------------------------------
Function: round_by_round_prep_node(state)

What it does:
1. For DSA rounds:
   - Generates 20-30 most asked topics (role-specific)
   - Provides practice questions
   - Includes LeetCode links
   - Differentiates SDE-1 vs SDE-2 topics

2. For System Design rounds:
   - Concepts to master
   - Common design questions
   - Resources and practice

3. For Behavioral rounds:
   - Company values/principles
   - STAR format stories
   - Common behavioral questions

Code Flow:
----------
def round_by_round_prep_node(state: InterviewPrepState) -> Dict[str, Any]:
    interview_rounds = state.get("interview_rounds", {})
    role_level = state.get("role_level", "SDE-1")
    resume_data = state.get("resume_data", {})
    
    dsa_prep = None
    system_design_prep = None
    behavioral_prep = None
    
    # If DSA round exists
    if "DSA" in interview_rounds.get("rounds", []):
        dsa_prompt = f"""
        Generate DSA preparation for {role_level} role.
        Include 20-30 most asked topics.
        Differentiate topics for SDE-1 vs SDE-2.
        Provide practice questions and resources.
        """
        dsa_response = client.chat.completions.create(...)
        dsa_prep = parse_dsa_prep(dsa_response.choices[0].message.content)
    
    # If System Design round exists
    if "System Design" in interview_rounds.get("rounds", []):
        sd_prompt = f"""
        Generate System Design preparation for {role_level} role.
        Include concepts, common questions, resources.
        """
        sd_response = client.chat.completions.create(...)
        system_design_prep = parse_system_design_prep(sd_response.choices[0].message.content)
    
    # If Behavioral round exists
    if "Behavioral" in interview_rounds.get("rounds", []):
        behavioral_prompt = f"""
        Generate Behavioral preparation.
        Include company values, STAR format stories, common questions.
        """
        behavioral_response = client.chat.completions.create(...)
        behavioral_prep = parse_behavioral_prep(behavioral_response.choices[0].message.content)
    
    return {
        "dsa_prep": dsa_prep,
        "system_design_prep": system_design_prep,
        "behavioral_prep": behavioral_prep
    }

NODE 4: COMMON QUESTIONS GENERATOR
-----------------------------------
Function: question_generator_node(state)

What it does:
1. Generates common interview questions for the role
2. Provides sample answers based on resume
3. Includes "Questions to Ask Interviewer"
4. Provides actionable tips

Code Flow:
----------
def question_generator_node(state: InterviewPrepState) -> Dict[str, Any]:
    job_data = state.get("job_data", {})
    resume_data = state.get("resume_data", {})
    company = job_data.get("company", "")
    role_level = state.get("role_level", "SDE-1")
    
    prompt = f"""
    Generate common interview questions for {role_level} at {company}.
    Include sample answers based on this resume: {resume_data}
    Also provide questions the candidate should ask the interviewer.
    """
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are an interview preparation expert"},
            {"role": "user", "content": prompt}
        ]
    )
    
    common_questions = parse_questions(response.choices[0].message.content)
    
    return {"common_questions": common_questions}

===================================================================================
                         SECTION 3: API INTEGRATION
===================================================================================

FRONTEND ‚Üí BACKEND:
-------------------
üìÅ FILE: frontend/src/pages/InterviewPrepPage.jsx

1. User clicks "Interview Prep" button
2. Navigates to /interview/:applicationId
3. useEffect triggers API call

Code:
-----
useEffect(() => {
    const abortController = new AbortController();
    
    const fetchInterviewPrep = async () => {
        try {
            setLoading(true);
            const response = await axios.get(
                `/api/interview/${applicationId}`,
                { signal: abortController.signal }
            );
            setPreparation(response.data);
        } catch (error) {
            if (error.name !== "AbortError") {
                setError(error.message);
            }
        } finally {
            setLoading(false);
        }
    };
    
    fetchInterviewPrep();
    
    return () => {
        abortController.abort();  // Cancel on unmount
    };
}, [applicationId]);

BACKEND ‚Üí AI SERVICE:
---------------------
üìÅ FILE: backend/routes/interview.js

1. Receives request with applicationId
2. Fetches application and job data
3. Fetches resume data
4. Calls AI service

Code:
-----
router.get("/:applicationId", authMiddleware, async (req, res) => {
    // 1. Set long timeout (3-5 minutes)
    req.setTimeout(300000);
    res.setTimeout(300000);
    
    // 2. Get application
    const application = await Application.findById(req.params.applicationId)
        .populate("jobId")
        .populate("userId");
    
    if (!application) {
        return res.status(404).json({ error: "Application not found" });
    }
    
    // 3. Get resume data
    const resume = await Resume.findOne({ userId: application.userId });
    const resumeData = await extractResumeData(resume.filename);
    
    // 4. Call AI service
    const preparation = await aiService.generateInterviewPrep(
        resumeData,
        application.jobId,
        application._id.toString()
    );
    
    // 5. Return structured data
    res.json({
        company_info: preparation.company_info,
        role_analysis: preparation.role_analysis,
        interview_rounds: preparation.interview_rounds,
        dsa_prep: preparation.dsa_prep,
        system_design_prep: preparation.system_design_prep,
        behavioral_prep: preparation.behavioral_prep,
        common_questions: preparation.common_questions,
        resources: preparation.resources,
        tips_for_success: preparation.tips_for_success
    });
});

AI SERVICE ENDPOINT:
--------------------
üìÅ FILE: AI/rag_service.py

@app.post("/interview/prepare")
async def prepare_interview(request: InterviewPrepRequest):
    resume_data = request.resume_data
    job_data = request.job_data
    application_id = request.application_id
    
    # 1. Build initial state
    initial_state = {
        "messages": [],
        "resume_data": resume_data,
        "job_data": job_data,
        "application_id": application_id,
        "company_info": None,
        "interview_links": None,
        "role_level": None,
        "interview_rounds": None,
        "dsa_prep": None,
        "system_design_prep": None,
        "behavioral_prep": None,
        "common_questions": None
    }
    
    # 2. Run LangGraph workflow (in separate thread to avoid blocking)
    result = await asyncio.to_thread(
        interview_prep_graph.invoke,
        initial_state
    )
    
    # 3. Return structured data
    return {
        "company_info": result.get("company_info"),
        "role_analysis": result.get("role_analysis"),
        "interview_rounds": result.get("interview_rounds"),
        "dsa_prep": result.get("dsa_prep"),
        "system_design_prep": result.get("system_design_prep"),
        "behavioral_prep": result.get("behavioral_prep"),
        "common_questions": result.get("common_questions"),
        "resources": result.get("resources"),
        "tips_for_success": result.get("tips_for_success")
    }

===================================================================================
                         SECTION 4: WEB SEARCH INTEGRATION
===================================================================================

TAVILY API:
-----------
üìÅ FILE: AI/tools_service.py

Tavily is an AI-optimized search engine used for:
- Company research
- Finding interview experiences
- Getting recent news

Code:
-----
def smart_web_search(query: str) -> str:
    try:
        # Try Tavily first
        tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
        response = tavily_client.search(
            query=query,
            search_depth="advanced",
            max_results=5
        )
        
        # Extract and format results
        results = []
        for result in response.results:
            results.append({
                "title": result.title,
                "url": result.url,
                "content": result.content
            })
        
        return format_search_results(results)
    except Exception as e:
        # Fallback to DuckDuckGo
        return duckduckgo_search(query)

EXTRACTING INTERVIEW LINKS:
---------------------------
Searches for:
- Reddit posts (r/cscareerquestions, r/ExperiencedDevs)
- Glassdoor interview reviews
- LeetCode company tags
- Blind app discussions

Filters results to find actual interview experiences.

===================================================================================
                         SECTION 5: FRONTEND DISPLAY
===================================================================================

üìÅ FILE: frontend/src/pages/InterviewPrepPage.jsx

LOADING STATE:
--------------
Shows progress steps:
- "Researching company..."
- "Analyzing interview rounds..."
- "Preparing DSA content..."
- "Generating questions..."

DISPLAY STRUCTURE:
-----------------
1. Company Information (collapsible)
2. Interview Rounds Overview
3. DSA Preparation (if applicable)
   - Topics list
   - Practice questions
   - Resources
4. System Design Preparation (if applicable)
   - Concepts
   - Common questions
   - Resources
5. Behavioral Preparation (if applicable)
   - STAR stories
   - Company values
   - Common questions
6. Common Interview Questions
   - Q&A with sample answers
7. Resources & Tips

CODE:
-----
{preparation.dsa_prep && (
    <section>
        <h2>DSA Preparation</h2>
        <div>
            <h3>Topics to Master</h3>
            <ul>
                {preparation.dsa_prep.topics.map(topic => (
                    <li key={topic}>{topic}</li>
                ))}
            </ul>
        </div>
        <div>
            <h3>Practice Questions</h3>
            {preparation.dsa_prep.questions.map(q => (
                <div key={q.id}>
                    <h4>{q.title}</h4>
                    <p>{q.description}</p>
                    <a href={q.link}>Practice on LeetCode</a>
                </div>
            ))}
        </div>
    </section>
)}

===================================================================================
                         SECTION 6: ASYNC PROCESSING
===================================================================================

WHY ASYNC?
----------
LangGraph.invoke() is synchronous and can take 3-5 minutes.
If called directly in FastAPI, it blocks the event loop.

SOLUTION:
---------
Use asyncio.to_thread() to run in separate thread:

async def prepare_interview(...):
    # Run synchronous LangGraph in thread pool
    result = await asyncio.to_thread(
        interview_prep_graph.invoke,
        initial_state
    )
    return result

This allows:
- FastAPI to handle other requests
- Health checks to work during processing
- Better resource utilization

===================================================================================
                         SECTION 7: ERROR HANDLING
===================================================================================

COMMON ERRORS:
--------------

1. Web Search Fails:
   - Cause: Tavily API down or rate limited
   - Solution: Fallback to DuckDuckGo
   - Impact: May have less relevant results

2. GPT-4 Timeout:
   - Cause: API slow or overloaded
   - Solution: Retry with exponential backoff
   - Impact: Longer processing time

3. Missing Resume Data:
   - Cause: Resume not processed yet
   - Solution: Wait for resume processing
   - Show error to user

4. Missing Job Data:
   - Cause: Job deleted or invalid
   - Solution: Return 404 error
   - Show error to user

===================================================================================
                         SECTION 8: OPTIMIZATION
===================================================================================

PERFORMANCE IMPROVEMENTS:
-------------------------

1. Parallel Node Execution:
   - Some nodes can run in parallel
   - Reduces total time

2. Caching:
   - Cache company info (doesn't change often)
   - Cache role analysis for same role level

3. Streaming:
   - Stream results as they're generated
   - Better user experience

4. Timeout Management:
   - Set appropriate timeouts
   - Handle gracefully

===================================================================================
                              END OF INTERVIEW PREP NOTES
===================================================================================

Key Takeaways:
- 4-node LangGraph workflow
- Web search for company research
- Role-specific content generation
- Async processing to avoid blocking
- Structured output for frontend display

